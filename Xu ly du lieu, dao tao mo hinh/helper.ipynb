{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mediapipe extract**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/bvinh/GDP/WLASL/dataset/nslt_3.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19080\\2841315299.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/Users/bvinh/GDP/WLASL/dataset/nslt_3.json\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/bvinh/GDP/WLASL/dataset/nslt_3.json'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os, sys, gc\n",
    "import time\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "# from tqdm.auto import tqdm\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from natsort import natsorted\n",
    "from glob import glob\n",
    "import math\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "N_FACE_LANDMARKS = 468\n",
    "N_BODY_LANDMARKS = 33\n",
    "N_HAND_LANDMARKS = 21\n",
    "\n",
    "\n",
    "class Counter(object):\n",
    "    # https://stackoverflow.com/a/47562583/\n",
    "    def __init__(self, initval=0):\n",
    "        self.val = multiprocessing.RawValue(\"i\", initval)\n",
    "        self.lock = multiprocessing.Lock()\n",
    "\n",
    "    def increment(self):\n",
    "        with self.lock:\n",
    "            self.val.value += 1\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        return self.val.value\n",
    "\n",
    "\n",
    "def process_body_landmarks(component, n_points):\n",
    "    kps = np.zeros((n_points, 3))\n",
    "    conf = np.zeros(n_points)\n",
    "    if component is not None:\n",
    "        landmarks = component.landmark\n",
    "        kps = np.array([[p.x, p.y, p.z] for p in landmarks])\n",
    "        conf = np.array([p.visibility for p in landmarks])\n",
    "    return kps, conf\n",
    "\n",
    "\n",
    "def process_other_landmarks(component, n_points):\n",
    "    kps = np.zeros((n_points, 3))\n",
    "    conf = np.zeros(n_points)\n",
    "    if component is not None:\n",
    "        landmarks = component.landmark\n",
    "        kps = np.array([[p.x, p.y, p.z] for p in landmarks])\n",
    "        conf = np.ones(n_points)\n",
    "    return kps, conf\n",
    "\n",
    "\n",
    "def get_holistic_keypoints(\n",
    "    frames, holistic=mp_holistic.Holistic(static_image_mode=False, model_complexity=2)\n",
    "):\n",
    "    \"\"\"\n",
    "    For videos, it's optimal to create with `static_image_mode=False` for each video.\n",
    "    https://google.github.io/mediapipe/solutions/holistic.html#static_image_mode\n",
    "\n",
    "    Static_image_mode => theo doi moc được detected từ đầu, không cần phát hiện khác cho đến khi mất dấu.\n",
    "    \"\"\"\n",
    "\n",
    "    keypoints = []\n",
    "    confs = []\n",
    "\n",
    "    for frame in frames:\n",
    "        results = holistic.process(frame)\n",
    "\n",
    "        body_data, body_conf = process_body_landmarks(\n",
    "            results.pose_landmarks, N_BODY_LANDMARKS\n",
    "        )\n",
    "        face_data, face_conf = process_other_landmarks(\n",
    "            results.face_landmarks, N_FACE_LANDMARKS\n",
    "        )\n",
    "        lh_data, lh_conf = process_other_landmarks(\n",
    "            results.left_hand_landmarks, N_HAND_LANDMARKS\n",
    "        )\n",
    "        rh_data, rh_conf = process_other_landmarks(\n",
    "            results.right_hand_landmarks, N_HAND_LANDMARKS\n",
    "        )\n",
    "\n",
    "        data = np.concatenate([body_data, face_data, lh_data, rh_data])\n",
    "        conf = np.concatenate([body_conf, face_conf, lh_conf, rh_conf])\n",
    "\n",
    "        keypoints.append(data)\n",
    "        confs.append(conf)\n",
    "\n",
    "    # TODO: Reuse the same object when this issue is fixed: https://github.com/google/mediapipe/issues/2152\n",
    "    holistic.close()\n",
    "    del holistic\n",
    "    gc.collect()\n",
    "\n",
    "    keypoints = np.stack(keypoints)\n",
    "    confs = np.stack(confs)\n",
    "    return keypoints, confs\n",
    "\n",
    "\n",
    "def gen_keypoints_for_frames(frames, save_path):\n",
    "\n",
    "    pose_kps, pose_confs = get_holistic_keypoints(frames)\n",
    "    body_kps = np.concatenate([pose_kps[:, :33, :], pose_kps[:, 501:, :]], axis=1)\n",
    "\n",
    "    confs = np.concatenate([pose_confs[:, :33], pose_confs[:, 501:]], axis=1)\n",
    "\n",
    "    d = {\"keypoints\": body_kps, \"confidences\": confs}\n",
    "\n",
    "    with open(save_path + \".pkl\", \"wb\") as f:\n",
    "        pickle.dump(d, f, protocol=4)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    with open(\"C:/Users/bvinh/GDP/WLASL/dataset/nslt_3.json\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    data.keys()\n",
    "    print(type(data.keys()))\n",
    "\n",
    "    list_id = list(data.keys())\n",
    "\n",
    "    dir_videos = \"C:/Users/bvinh/GDP/WLASL/dataset/cutvideo/\"\n",
    "    save_pkl = \"D:/Personalproject/OpenHands/data_out\"\n",
    "    dir_input = []\n",
    "    save_dirs = []\n",
    "    for idx in range(0, len(list_id)):\n",
    "        dir_video = os.path.join(dir_videos, list_id[idx] + \".mp4\")\n",
    "        save_dir = os.path.join(save_pkl, list_id[idx])\n",
    "        dir_input.append(dir_video)\n",
    "        save_dirs.append(save_dir)\n",
    "        frames = []\n",
    "        vidcap = cv2.VideoCapture(dir_video)\n",
    "        while vidcap.isOpened():\n",
    "            success, img = vidcap.read()\n",
    "            if not success:\n",
    "                print(\"No frame available\")\n",
    "                break\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, (640,480))\n",
    "\n",
    "            frames = np.asarray(frames.append(img))\n",
    "            print(np.shape(frames))\n",
    "            print(type(frames))\n",
    "            gen_keypoints_for_frames(frames, save_dir)\n",
    "        print(\"=\" * 30 + \"{}\".format(\"Done: \" + str(idx))+ \"=\"*30)\n",
    "    print(\"Done!!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test video**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not success img in video\n",
      "<class 'NoneType'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "video_path = \"D:\\Personalproject\\OpenHands\\data_in/17023.mp4\"\n",
    "vidcap = cv2.VideoCapture(video_path)\n",
    "frames = []\n",
    "while vidcap.isOpened():\n",
    "    success, imga = vidcap.read()\n",
    "    if not success:\n",
    "        print(\"Not success img in video\")\n",
    "        break\n",
    "    img = cv2.cvtColor(imga, cv2.COLOR_BGR2RGB)\n",
    "    frames.append(img)\n",
    "\n",
    "vidcap.release()\n",
    "print(type(imga))\n",
    "print(type(img))\n",
    "print(type(frames))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Copy video to folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "DIR = \"D:\\Personalproject\\OpenHands\\data_in\"\n",
    "SAVE_DIR = \"D:\\Personalproject\\OpenHands\\data_out\"\n",
    "for file in os.listdir(DIR):\n",
    "    file_path = os.path.join(DIR,file)\n",
    "    save_path = os.path.join(SAVE_DIR, file)\n",
    "    shutil.copy(file_path, save_path)\n",
    "    print(\"Done\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Personalproject/dataset/HAO/Video/fine\n",
      "==============================fine: 9\n",
      "D:/Personalproject/dataset/HAO/Video/want\n",
      "==============================want: 9\n",
      "D:/Personalproject/dataset/HAO/Video/right\n",
      "==============================right: 9\n",
      "D:/Personalproject/dataset/HAO/Video/help\n",
      "==============================help: 14\n",
      "D:/Personalproject/dataset/HAO/Video/hurt\n",
      "==============================hurt: 5\n",
      "D:/Personalproject/dataset/HAO/Video/good\n",
      "==============================good: 10\n",
      "D:/Personalproject/dataset/HAO/Video/hospital\n",
      "==============================hospital: 7\n",
      "D:/Personalproject/dataset/HAO/Video/because\n",
      "==============================because: 10\n",
      "D:/Personalproject/dataset/HAO/Video/head\n",
      "==============================head: 6\n",
      "D:/Personalproject/dataset/HAO/Video/left\n",
      "==============================left: 5\n",
      "D:/Personalproject/dataset/HAO/Video/shoulder\n",
      "==============================shoulder: 4\n",
      "D:/Personalproject/dataset/HAO/Video/throat\n",
      "==============================throat: 5\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import json, shutil\n",
    "\n",
    "path_json = \"D:/Personalproject/OpenHands/HAO_lost_video.json\"\n",
    "\n",
    "with open(path_json, \"r\") as f:\n",
    "    HAO_data = json.load(f)\n",
    "\n",
    "DIR_DATASET = \"D:/Personalproject/GDP/WLASL/dataset/videos/\"\n",
    "DIR_SAVE = \"D:/Personalproject/dataset/HAO/Video\"\n",
    "\n",
    "for idx in range(len(HAO_data)):\n",
    "    gloss =  HAO_data[idx]['gloss']\n",
    "    list_key = HAO_data[idx].keys()\n",
    "    # print(list_key)\n",
    "    gloss_folder = DIR_SAVE + \"/{}\".format(gloss)\n",
    "    print(gloss_folder)\n",
    "    # print(len(gloss_folder))\n",
    "    # os.mkdir(gloss_folder)\n",
    "    # print(\"Done {}\".format(gloss))\n",
    "\n",
    "    for idy in range(len(HAO_data[idx]['video available'])):\n",
    "        video_id = HAO_data[idx]['video available'][idy]\n",
    "        \n",
    "        DIR_VIDEO = DIR_DATASET + \"{}.mp4\".format(video_id)\n",
    "        SAVE_VIDEO =  gloss_folder + \"/{}.mp4\".format(video_id)\n",
    "        shutil.copy(DIR_VIDEO, SAVE_VIDEO)\n",
    "    print(\"=\"*30 + \"{}\".format(gloss) + \": \" + \"{}\".format( len(HAO_data[idx]['video available'])))\n",
    "print(\"Done!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "\n",
    "path_json = \"D:\\Personalproject\\GDP\\WLASL\\dataset\\WLASL_v0.3.json\"\n",
    "with open(path_json, \"r\") as f:\n",
    "    wlasl = json.load(f)\n",
    "\n",
    "\n",
    "dir_dataset = \"D:\\Personalproject\\OpenHands\\datasets/wlasl_data\"\n",
    "os.chdir(dir_dataset)\n",
    "\n",
    "gloss = wlasl[1][\"gloss\"]\n",
    "os.makedirs(gloss)\n",
    "for idx in range(len(wlasl)):\n",
    "    gloss = wlasl[idx][\"gloss\"]\n",
    "    \n",
    "    # os.mkdir(path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    }
   ],
   "source": [
    "gloss_dict = ['allergy', 'appointment', 'arm', 'bad', 'bell', 'beside', 'between', 'blood', 'bone', 'brain', 'break', 'burp', 'buy', 'can', 'check', 'cool', 'cost', 'deaf', 'diarrhea', 'dizzy', 'doctor', \"don't want\", 'ear', 'everyday', 'eyes', 'face', 'feel', 'fine', 'forget', 'good', 'hard', 'head', 'headache', 'help', 'hospital', 'hot', 'hurt', 'infection', 'left', 'medicine', 'my', 'neck', 'normal', 'not', 'nurse', 'often', 'pain', 'pneumonia', 'recent', 'right', 'shoulder', 'sick', 'skin', 'sometimes', 'sore throat', 'surgeon', 'surgery', 'teeth', 'throat', 'tired', 'vomit', 'want', 'where', \"i\", \"because\"]\n",
    "\n",
    "glos_dict_88 = ['allergy', 'appointment', 'arm', 'bad', 'bell', 'beside', 'between', 'blood', 'bone', 'brain', 'break', 'burp', 'buy', 'can', 'check', 'cool', 'cost', 'deaf', 'diarrhea', 'dizzy', 'doctor', \"don't want\", 'ear', 'everyday', 'eyes', 'face', 'feel', 'fine', 'forget', 'good', 'hard', 'head', 'headache', 'help', 'hospital', 'hot', 'hurt', 'infection', 'left', 'medicine', 'my', 'neck', 'normal', 'not', 'nurse', 'often', 'pain', 'pneumonia', 'recent', 'right', 'shoulder', 'sick', 'skin', 'sometimes', 'sore throat', 'surgeon', 'surgery', 'teeth', 'throat', 'tired', 'vomit', 'want', 'where', \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\" ,\"i\" ,\"k\" , \"l\" , \"m\", \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\"]\n",
    "\n",
    "\n",
    "print(len(gloss_dict))\n",
    "\n",
    "# gloss_5 = [\"doctor\", \"deaf\", \"teeth\", \"help\", \"pain\", \"medicine\"]\n",
    "# gloss_10 = [\"doctor\", \"deaf\", \"help\", \"pain\", \"medicine\", \"hospital\", \"allergy\", \"can\", \"not\", \"my\"]\n",
    "# gloss_15 = [\"appointment\", \"\"]\n",
    "# gloss_30 = []\n",
    "# gloss_50 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['allergy', 'appointment', 'arm', 'bad', 'because', 'bell', 'beside', 'between', 'blood', 'bone', 'brain', 'break', 'burp', 'buy', 'can', 'check', 'cool', 'cost', 'deaf', 'diarrhea', 'dizzy', 'doctor', \"don't want\", 'ear', 'everyday', 'eyes', 'face', 'feel', 'fine', 'forget', 'good', 'hard', 'head', 'headache', 'help', 'hospital', 'hot', 'hurt', 'i', 'infection', 'left', 'medicine', 'my', 'neck', 'normal', 'not', 'nurse', 'often', 'pain', 'pneumonia', 'recent', 'right', 'shoulder', 'sick', 'skin', 'sometimes', 'sore throat', 'surgeon', 'surgery', 'teeth', 'throat', 'tired', 'vomit', 'want', 'where']\n"
     ]
    }
   ],
   "source": [
    "gloss_dict.sort()\n",
    "print(gloss_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create .json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "gloss_5 = [\"deaf\", \"allergy\", \"i\", \"often\", \"tired\"]\n",
    "\n",
    "gloss_10 = [\"allergy\", \"deaf\", \"diarrhea\",\"infection\",\"i\", \"pneumonia\", \"doctor\", \"sore throat\", \"tired\", \"check\"]\n",
    "\n",
    "\n",
    "\n",
    "print(len(gloss_10))\n",
    "\n",
    "\n",
    "gloss_20 = ['allergy', 'because', 'buy', 'check', 'deaf', 'diarrhea', 'dizzy' , 'doctor', \"hospital\",'head', 'help', 'i', 'infection', 'medicine', 'often', 'pneumonia', 'sore throat', 'throat', 'tired',  'vomit','want', 'hurt', 'shoulder', 'right', 'left', \"fine\", \"good\"]\n",
    "\n",
    "print(len(gloss_20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['because', 'buy', 'dizzy', 'hospital', 'head', 'help', 'medicine', 'often', 'throat', 'vomit', 'want', 'hurt', 'shoulder', 'right', 'left', 'fine', 'good']\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "split_gloss = []\n",
    "for gloss in gloss_20:\n",
    "    if gloss not in gloss_10:\n",
    "        split_gloss.append(gloss)\n",
    "print(split_gloss)\n",
    "print(len(split_gloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['buy', 'dizzy', 'medicine', 'often', 'vomit']\n",
      "['allergy', 'deaf', 'diarrhea', 'infection', 'i', 'pneumonia', 'doctor', 'sore throat', 'tired', 'check', 'buy', 'dizzy', 'medicine', 'often', 'vomit']\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "gloss_N =[]\n",
    "choose_gloss = [split_gloss[1], split_gloss[2],  split_gloss[6], split_gloss[7], split_gloss[9]]\n",
    "print(choose_gloss)\n",
    "\n",
    "gloss_N = gloss_10 + choose_gloss\n",
    "print(gloss_N)\n",
    "print(len(gloss_N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['because', 'hospital', 'head', 'help', 'throat', 'want', 'hurt', 'shoulder', 'right', 'left', 'fine', 'good']\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "gloss_H = []\n",
    "for gloss in gloss_20:\n",
    "    if gloss not in gloss_N:\n",
    "        gloss_H.append(gloss)\n",
    "print(gloss_H)\n",
    "print(len(gloss_H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['because', 'hospital', 'head', 'help', 'throat', 'want', 'hurt', 'shoulder', 'right', 'left', 'fine', 'good']\n",
      "['allergy', 'deaf', 'diarrhea', 'infection', 'i', 'pneumonia', 'doctor', 'sore throat', 'tired', 'check', 'buy', 'dizzy', 'medicine', 'often', 'vomit']\n"
     ]
    }
   ],
   "source": [
    "print(gloss_H)\n",
    "print(gloss_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gloss_dict = gloss_H + gloss_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================final_json==============================\n",
      "12\n",
      "Done create .json!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "with open(\"D:\\Personalproject\\GDP\\WLASL\\dataset\\WLASL_v0.3.json\", \"r\") as f:\n",
    "    wlasl = json.load(f)\n",
    "\n",
    "rewrite = []\n",
    "gloss_class = []\n",
    "i = 0\n",
    "for idx in range(len(wlasl)):\n",
    "  gloss = wlasl[idx][\"gloss\"]\n",
    "  video_of_gloss = wlasl[idx][\"instances\"]\n",
    "\n",
    "  if gloss in gloss_H:\n",
    "    classes = {\"gloss\": gloss, \"instances\": video_of_gloss}\n",
    "    rewrite.append(classes)\n",
    "\n",
    "\n",
    "print(\"=\"*30 + \"{}\".format(\"final_json\") + \"=\"*30)\n",
    "\n",
    "##Sorted rewrite with  alphabetically\n",
    "rewrite = sorted(rewrite, key=lambda k: k['gloss'])\n",
    "\n",
    "##Write .json file\n",
    "json_object = json.dumps(rewrite, indent=4)\n",
    "save_dir = \"D:\\Personalproject\\OpenHands\\WLASL_gloss_H.json\"\n",
    "with open(save_dir, \"w\") as outfile:\n",
    "  outfile.write(json_object)\n",
    "print(len(rewrite))\n",
    "print(\"Done create .json!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['because', 'fine', 'good', 'head', 'help', 'hospital', 'hurt', 'left', 'right', 'shoulder', 'throat', 'want']\n",
      "['because', 'fine', 'good', 'head', 'help', 'hospital', 'hurt', 'left', 'right', 'shoulder', 'throat', 'want']\n",
      "\n",
      "\n",
      "['allergy', 'buy', 'check', 'deaf', 'diarrhea', 'dizzy', 'doctor', 'i', 'infection', 'medicine', 'often', 'pneumonia', 'sore throat', 'tired', 'vomit']\n",
      "['allergy', 'buy', 'check', 'deaf', 'diarrhea', 'dizzy', 'doctor', 'i', 'infection', 'medicine', 'often', 'pneumonia', 'sore throat', 'tired', 'vomit']\n"
     ]
    }
   ],
   "source": [
    "##Check gloss\n",
    "#===== gloss H =====\n",
    "with open(\"D:/Personalproject/OpenHands/WLASL_gloss_H.json\", \"r\") as f:\n",
    "    wlasl_H = json.load(f)\n",
    "\n",
    "gloss_H_check = []\n",
    "for idx in range(len(wlasl)):\n",
    "    gloss_H_check.append(wlasl[idx][\"gloss\"])\n",
    "\n",
    "gloss_H = sorted(gloss_H)\n",
    "print(gloss_H)\n",
    "print(gloss_H_check)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "#===== gloss H =====\n",
    "with open(\"D:/Personalproject/OpenHands/WLASL_gloss_N.json\", \"r\") as f:\n",
    "    wlasl_N = json.load(f)\n",
    "\n",
    "gloss_N_check = []\n",
    "for idy in range(len(wlasl_N)):\n",
    "    gloss_N_check.append(wlasl_N[idy][\"gloss\"])\n",
    "\n",
    "gloss_N = sorted(gloss_N)\n",
    "print(gloss_N)\n",
    "print(gloss_N_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check video available in datasets videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video avalable in dataset: 11986\n",
      "video_in_wlasl: 365\n",
      "video_lost: 158\n",
      "Num video available for wlasl_27: 207\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os, shutil, sys\n",
    "import numpy as np\n",
    "\n",
    "DIR_DATASET = \"D:/Personalproject/GDP/WLASL/dataset/videos\"\n",
    "\n",
    "path_json = \"D:/Personalproject/OpenHands/WLASL_27.json\"\n",
    "\n",
    "with open(path_json, \"r\") as f:\n",
    "    wlasl = json.load(f)\n",
    "\n",
    "video_available = []\n",
    "video_in_wlasl = []\n",
    "video_loss_27 =[]\n",
    "\n",
    "for file in os.listdir(DIR_DATASET):\n",
    "    video_available.append(file.replace(\".mp4\", \"\"))\n",
    "\n",
    "print(\"Video avalable in dataset: {}\".format(len(video_available)))\n",
    "\n",
    "for idx in range(len(wlasl)):\n",
    "    gloss =  wlasl[idx][\"gloss\"]\n",
    "    # print(\" ===== Class: {}  have {} videos =====\".format(gloss, len(wlasl[idx][\"instances\"])))\n",
    "    video_id_lost = []\n",
    "    for idy in range(len(wlasl[idx][\"instances\"])):\n",
    "        video_id = wlasl[idx][\"instances\"][idy][\"video_id\"]\n",
    "        video_in_wlasl.append(video_id)\n",
    "        if video_id not in video_available:\n",
    "            video_id_lost.append(video_id)\n",
    "            video_loss_27.append(video_id)\n",
    "    # print(\"Have {} lost video in dataset availabe\".format(len(video_id_lost)))\n",
    "    # print(\"Video_id_lost: {}\".format(video_id_lost))\n",
    "\n",
    "# print(\"Have {} lost video in dataset availabe\".format(len(video_id_lost)))\n",
    "print(\"video_in_wlasl: {}\".format(len(video_in_wlasl)))\n",
    "print(\"video_lost: {}\".format(len(video_loss_27)))\n",
    "print(\"Num video available for wlasl_27: {}\".format(len(video_in_wlasl) - len(video_loss_27)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get video_id -  get url_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os, shutil, sys\n",
    "import numpy as np\n",
    "\n",
    "DIR_DATASET = \"D:/Personalproject/GDP/WLASL/dataset/videos\"\n",
    "\n",
    "path_json = \"D:/Personalproject/OpenHands/WLASL_27.json\"\n",
    "\n",
    "with open(path_json, \"r\") as f:\n",
    "    wlasl = json.load(f)\n",
    "\n",
    "video_available = []\n",
    "video_in_wlasl = []\n",
    "video_id_lost = []\n",
    "num_id_lost_per_gloss = []\n",
    "\n",
    "for file in os.listdir(DIR_DATASET):\n",
    "    video_available.append(file.replace(\".mp4\", \"\"))\n",
    "\n",
    "print(\"Video avalable in dataset: {}\".format(len(video_available)))\n",
    "# print(\"Gloss in wlasl_custom: {}\".format(len(wlasl)))\n",
    "print(\"\\n\")\n",
    "\n",
    "# for idx in range(len(wlasl)):\n",
    "for idx in range(len(wlasl)-26):\n",
    "    gloss =  wlasl[idx][\"gloss\"]\n",
    "    print(\" ===== Class: {}  have {} videos =====\".format(gloss, len(wlasl[idx][\"instances\"])))\n",
    "    \n",
    "    video_id_lost_per_gloss = []\n",
    "    video_of_gloss_indataset = []\n",
    "\n",
    "    lost_video_url = []\n",
    "    for idy in range(len(wlasl[idx][\"instances\"])):\n",
    "        video_id = wlasl[idx][\"instances\"][idy][\"video_id\"]\n",
    "        video_in_wlasl.append(video_id)\n",
    "        id_url = {}\n",
    "        if video_id not in video_available:\n",
    "            video_id_lost_per_gloss.append(video_id)\n",
    "            id_url ={video_id, wlasl[idx][\"instances\"][idy][\"url\"]}\n",
    "            lost_video_url.append(id_url)\n",
    "            video_id_lost.append(video_id)\n",
    "        else:\n",
    "            video_of_gloss_indataset.append(video_id)\n",
    "        \n",
    "        \n",
    "    d = {\"gloss\" :gloss, \"Num video of gloss\": len(wlasl[idx][\"instances\"]) ,\"Num video lost\" : len(video_id_lost_per_gloss), \"Video_id_lost\": lost_video_url, \"video_available\": video_of_gloss_indataset}\n",
    "    # d = {\"gloss\" :gloss, \"Num video of gloss\": len(wlasl[idx][\"instances\"]) ,\"Num video lost\" : len(video_id_lost_per_gloss), lost_video_url, \"video_available\": video_of_gloss_indataset}\n",
    "\n",
    "    num_id_lost_per_gloss.append(d)\n",
    "# print(num_id_lost_per_gloss)\n",
    "\n",
    "\n",
    "\n",
    "# #     print(\"Have {} lost video in dataset\".format(len(video_id_lost_per_gloss)))\n",
    "# #     print(\"ID video lost of gloss {}: {}\".format(gloss,video_id_lost_per_gloss))\n",
    "# #     print(\"\\n\")\n",
    "\n",
    "num_id_lost_per_gloss = sorted(num_id_lost_per_gloss, key=lambda k: k['Num video lost'], reverse=True)\n",
    "# json_object = json.dumps(num_id_lost_per_gloss, indent=4)\n",
    "\n",
    "print(num_id_lost_per_gloss)\n",
    "\n",
    " \n",
    "# # Writing to sample.json\n",
    "with open(\"D:/Personalproject/OpenHands/Video_27_loss_with_url.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "# print(\"In WLASL_custom.json have {} videos and lost {} videos\".format(len(video_in_wlasl), len(video_id_lost)))\n",
    "\n",
    "# # print(\"\\n\")\n",
    "# # print(\"Num id lost per class: {}\".format(num_id_lost_per_gloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import numpy as np\n",
    "\n",
    "DIR_DATASET = \"D:/Personalproject/GDP/WLASL/dataset/videos\"\n",
    "\n",
    "path_json = \"D:/Personalproject/OpenHands/WLASL_27.json\"\n",
    "\n",
    "with open(path_json, \"r\") as f:\n",
    "    wlasl = json.load(f)\n",
    "\n",
    "video_available = []\n",
    "video_in_wlasl = []\n",
    "video_id_lost = []\n",
    "anal_data = []\n",
    "\n",
    "for file in os.listdir(DIR_DATASET):\n",
    "    video_available.append(file.replace(\".mp4\", \"\"))\n",
    "\n",
    "print(\"Video avalable in dataset: {}\".format(len(video_available)))\n",
    "print(\"\\n\")\n",
    "\n",
    "for idx in range(len(wlasl)):\n",
    "    gloss = wlasl[idx][\"gloss\"]\n",
    "    print(\" ===== Class: {}  have {} videos =====\".format(gloss, len(wlasl[idx][\"instances\"])))\n",
    "    \n",
    "    video_id_lost_per_gloss = []\n",
    "    video_of_gloss_indataset = []\n",
    "    id_url_per_gloss = []\n",
    "    for idy in range(len(wlasl[idx][\"instances\"])):\n",
    "        video_id = wlasl[idx][\"instances\"][idy][\"video_id\"]\n",
    "        video_in_wlasl.append(video_id)\n",
    "        id_url_= {}\n",
    "        \n",
    "        if video_id not in video_available:\n",
    "            video_id_lost_per_gloss.append(video_id)\n",
    "            url_video = wlasl[idx][\"instances\"][idy][\"url\"]\n",
    "            video_id_lost.append(video_id)\n",
    "            id_url = {video_id: url_video}\n",
    "            id_url_per_gloss.append(id_url)\n",
    "            \n",
    "        else:\n",
    "            video_of_gloss_indataset.append(video_id)\n",
    "\n",
    "    print(\"Num video lost of gloss {}: {}\".format(gloss,len(video_id_lost_per_gloss)))\n",
    "    d = {\"gloss\" : gloss, \"Num video of gloss\": len(wlasl[idx][\"instances\"]), \n",
    "        \"Num video lost\": len(video_id_lost_per_gloss), \"Video id lost\": id_url_per_gloss, \"video available\":video_of_gloss_indataset}\n",
    "    anal_data.append(d)\n",
    "\n",
    "anal_data =sorted(anal_data, key=lambda k: k['Num video lost'], reverse=True)\n",
    "json_object = json.dumps(anal_data, indent=4)\n",
    "\n",
    "with open(\"D:/Personalproject/OpenHands/Video_27_loss_with_url.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Hao + Nghia json loss video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "15\n",
      "Done Hao!\n",
      "Done Nghia!\n"
     ]
    }
   ],
   "source": [
    "import json, os\n",
    "import numpy as np\n",
    "\n",
    "DIR_Hao_dataset = \"D:\\Personalproject\\OpenHands\\WLASL_gloss_H.json\"\n",
    "DIR_Nghia_dataset = \"D:\\Personalproject\\OpenHands\\WLASL_gloss_N.json\"\n",
    "\n",
    "DIR_URL_lost_dataset = \"D:\\Personalproject\\OpenHands\\Video_27_loss_with_url.json\"\n",
    "\n",
    "\n",
    "with open(DIR_URL_lost_dataset, \"r\") as f:\n",
    "    url_video = json.load(f)\n",
    "\n",
    "\n",
    "with open(DIR_Hao_dataset, \"r\") as f:\n",
    "    Hao_data = json.load(f)\n",
    "\n",
    "\n",
    "with open(DIR_Nghia_dataset, \"r\") as f:\n",
    "    Nghia_data = json.load(f)\n",
    "\n",
    "Hao_lost_json = []\n",
    "Nghia_lost_json = []\n",
    "for idx in range(len(url_video)):\n",
    "    gloss = url_video[idx][\"gloss\"]\n",
    "    # print(gloss)\n",
    "    if gloss in gloss_H:\n",
    "        Hao_lost_json.append(url_video[idx])\n",
    "    \n",
    "    if gloss in gloss_N:\n",
    "        Nghia_lost_json.append(url_video[idx])\n",
    "\n",
    "print(len(Hao_lost_json))\n",
    "print(len(Nghia_lost_json))\n",
    "\n",
    "H_json_object = json.dumps(Hao_lost_json, indent=4)\n",
    "N_json_object = json.dumps(Nghia_lost_json, indent=4)\n",
    "\n",
    "with open(\"D:/Personalproject/OpenHands/Hao_lost_video.json\", \"w\") as outfile1:\n",
    "  outfile1.write(H_json_object)\n",
    "\n",
    "print(\"Done Hao!\")\n",
    "\n",
    "\n",
    "with open(\"D:/Personalproject/OpenHands/Nghia_lost_video.json\", \"w\") as outfile2:\n",
    "  outfile2.write(N_json_object)\n",
    "\n",
    "print(\"Done Nghia!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Hao!\n",
      "173\n",
      "153\n"
     ]
    }
   ],
   "source": [
    "import json, os\n",
    "import numpy as np\n",
    "\n",
    "with open(\"D:/Personalproject/OpenHands/Hao_lost_video.json\", \"r\") as f:\n",
    "    Hao_lost = json.load(f)\n",
    "print(\"Done Hao!\")\n",
    "\n",
    "\n",
    "with open(\"D:/Personalproject/OpenHands/Nghia_lost_video.json\", \"r\") as z:\n",
    "    Nghia_lost = json.load(z)\n",
    "\n",
    "count_H = 0\n",
    "count_N = 0\n",
    "\n",
    "for idx in range(len(Hao_lost)):\n",
    "    count_H += (len(Hao_lost[idx][\"Video id lost\"]) +  len(Hao_lost[idx][\"video available\"]))\n",
    "print(count_H)\n",
    "\n",
    "for idy in range(len(Nghia_lost)):\n",
    "    count_N += (len(Nghia_lost[idy][\"Video id lost\"]) + len(Nghia_lost[idx][\"video available\"]))\n",
    "print(count_N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "gloss_5 = [\"deaf\", \"allergy\", \"i\", \"often\", \"tired\"]\n",
    "\n",
    "gloss_10 = [\"allergy\", \"deaf\", \"diarrhea\",\"infection\",\"i\", \"pneumonia\", \"doctor\", \"sore throat\", \"tired\", \"check\"]\n",
    "\n",
    "\n",
    "print(len(gloss_10))\n",
    "\n",
    "\n",
    "gloss_20 = ['allergy', 'because', 'buy', 'check', 'deaf', 'diarrhea', 'dizzy' , 'doctor', \"hospital\",'head', 'help', 'i', 'infection', 'medicine', 'often', 'pneumonia', 'sore throat', 'throat', 'tired',  'vomit','want', 'hurt', 'shoulder', 'right', 'left', \"fine\", \"good\"]\n",
    "print(len(gloss_20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read PKL FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> format keypoint[num_frame][75keypoints]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbr_gloss:  8\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# DIR_PKL_FILE = \"D:/Personalproject/dataset/Nghia/data_pkl\"\n",
    "\n",
    "# deaf - medicine - sore throat - tired - i - allergy - often - check\n",
    "\n",
    "f = open(\"D:\\Personalproject\\OpenHands\\json_output\\WLASL_gloss_N.json\", \"r\")\n",
    "\n",
    "glosses = json.load(f)\n",
    "\n",
    "list_test = [\"deaf\", \"medicine\", \"sore throat\", \"tired\", \"i\", \"allergy\", \"often\", \"check\"]\n",
    "print(\"Numbr_gloss: \", len(list_test))\n",
    "H_json_object = []\n",
    "\n",
    "for idx in range(len(glosses)):\n",
    "    gloss = glosses[idx][\"gloss\"]\n",
    "    if gloss in list_test:\n",
    "        H_json_object.append(glosses[idx])\n",
    "    \n",
    "print(len(H_json_object))\n",
    "    # print(gloss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewrite = sorted(H_json_object, key=lambda k: k['gloss'])\n",
    "\n",
    "##Write .json file\n",
    "json_object = json.dumps(rewrite, indent=4)\n",
    "save_dir = \"D:\\Personalproject\\OpenHands\\json_output\\LSTM_H.json\"\n",
    "with open(save_dir, \"w\") as outfile:\n",
    "  outfile.write(json_object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== allergy\n",
      "Variance_id of gloss: <allergy>:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "\n",
      "============================== check\n",
      "10184\n",
      "10186\n",
      "10192\n",
      "10193\n",
      "10199\n",
      "Variance_id of gloss: <check>:  [0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1]\n",
      "\n",
      "\n",
      "============================== deaf\n",
      "Variance_id of gloss: <deaf>:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "\n",
      "============================== i\n",
      "Variance_id of gloss: <i>:  [0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "\n",
      "============================== medicine\n",
      "Variance_id of gloss: <medicine>:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "\n",
      "============================== often\n",
      "Variance_id of gloss: <often>:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "\n",
      "============================== sore throat\n",
      "Variance_id of gloss: <sore throat>:  [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "\n",
      "============================== tired\n",
      "Variance_id of gloss: <tired>:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "\n",
      "110\n",
      "105\n",
      "[10, 17, 23, 7, 18, 11, 8, 16]\n"
     ]
    }
   ],
   "source": [
    "z =  open(\"D:\\Personalproject\\OpenHands\\json_output\\LSTM_H.json\", \"r\")\n",
    "lstm_h = json.load(z)\n",
    "\n",
    "\n",
    "video_in_lstm = []\n",
    "video_per_gloss = []\n",
    "video_per_gloss_variance_0 = []\n",
    "# variation_id = []\n",
    "a =0\n",
    "b = 0 \n",
    "c = 0 \n",
    "for idx in range(len(lstm_h)):\n",
    "    gloss = lstm_h[idx][\"gloss\"]\n",
    "    instance = lstm_h[idx][\"instances\"]\n",
    "    a =0\n",
    "    b = 0 \n",
    "    c = 0 \n",
    "    variation_id = []\n",
    "    print(\"=\" * 30 + \" {}\".format(gloss))\n",
    "    for idy in range(len(instance)):\n",
    "        if instance[idy][\"variation_id\"] == 0:\n",
    "            video_per_gloss_variance_0.append(instance[idy][\"video_id\"])\n",
    "        else:\n",
    "            print(instance[idy][\"video_id\"])\n",
    "        \n",
    "        video_in_lstm.append(instance[idy][\"video_id\"])\n",
    "        variation_id.append(instance[idy][\"variation_id\"])\n",
    "    print(\"Variance_id of gloss: <{}>:  {}\".format(gloss, variation_id))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    video_per_gloss.append(len(instance))\n",
    "\n",
    "\n",
    "\n",
    "print(len(video_in_lstm))\n",
    "print(len(video_per_gloss_variance_0))\n",
    "print(video_per_gloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "<class 'str'>\n",
      "29\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "# Open a file\n",
    "DIR_LSTM_PKL = \"D:/Personalproject/dataset/Nghia/data_pkl\"\n",
    "dirs = os.listdir(DIR_LSTM_PKL)\n",
    "print(len(dirs))\n",
    "print(type(dirs[0]))\n",
    "# This would print all the files and directories\n",
    "\n",
    "video_not_exist = []\n",
    "video_exist = []\n",
    "\n",
    "for idx in range(len(video_per_gloss_variance_0)):\n",
    "    pkl_file = video_per_gloss_variance_0[idx] + \".pkl\"\n",
    "    if pkl_file not in dirs:\n",
    "        video_not_exist.append(video_per_gloss_variance_0[idx])\n",
    "    else:\n",
    "        video_exist.append(video_per_gloss_variance_0[idx])\n",
    "\n",
    "print(len(video_not_exist))\n",
    "print(len(video_exist))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n"
     ]
    }
   ],
   "source": [
    "import json, shutil\n",
    "\n",
    "\n",
    "\n",
    "DIR_LSTM_PKL = \"D:/Personalproject/dataset/Nghia/data_pkl\"\n",
    "DIR_SAVE = \"D:/Personalproject/dataset/lstm_pkl\"\n",
    "\n",
    "\n",
    "count = 0\n",
    "for idx in range(len(video_exist)):\n",
    "    video_id = video_exist[idx]\n",
    "    DIR_VIDEO = DIR_LSTM_PKL + \"/{}.pkl\".format(video_id)\n",
    "    SAVE_VIDEO =  DIR_SAVE + \"/{}.pkl\".format(video_id)\n",
    "    shutil.copy(DIR_VIDEO, SAVE_VIDEO)\n",
    "    count +=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "dir_pkl = \"D:/Personalproject/dataset/Nghia/data_pkl/08487.pkl\"\n",
    "\n",
    "data = pickle. load(open(dir_pkl, \"rb\"))\n",
    "keypoints = data[\"keypoints\"]\n",
    "\n",
    "mediapipe_holistic_minimal_27 =  [0, 2, 5, 11, 12, 13, 14, 33, 37, 38, 41, 42, 45, 46, 49, 50, 53, 54, 58, 59, 62, 63, 66, 67, 70, 71, 74],\n",
    "points =  list(mediapipe_holistic_minimal_27)\n",
    "\n",
    "minimal_27 = []\n",
    "\n",
    "for idx in range(len(keypoints)):\n",
    "    frame = keypoints[idx]\n",
    "    d = []\n",
    "    for idy in points:\n",
    "        d.append(frame[idy])\n",
    "    reshape = np.reshape(d, (27,3))\n",
    "    # print(np.shape(reshape))\n",
    "    minimal_27.append(reshape)\n",
    "print(\"minimal_27: \", np.shape(minimal_27))\n",
    "\n",
    "total_lm3d = np.array(minimal_27)\n",
    "dir_Save = \"D:\\Personalproject\\OpenHands\\data_out\"\n",
    "save_path = \"{}/{}\".format(dir_Save,\"08487\")\n",
    "np.save(save_path,total_lm3d)\n",
    "print(\"Done!\")\n",
    "\n",
    "# minimal_27 = np.reshape\n",
    "# print(np.shape(minimal_27))\n",
    "# minimal_27\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import numpy as np\n",
    "import os, glob\n",
    "\n",
    "video_np = []\n",
    "\n",
    "for file in os.listdir(\"D:\\Personalproject\\OpenHands\\data_out\"):\n",
    "    video_name = file.split(\".\")[0]\n",
    "    video_np.append(video_name)\n",
    "\n",
    "print(len(video_np))\n",
    "\n",
    "\n",
    "lstm_h = json.load(open(\"D:\\Personalproject\\OpenHands\\json_output\\LSTM_H.json\", \"r\"))\n",
    "\n",
    "show_time = []\n",
    "\n",
    "for idx in range(len(lstm_h)):\n",
    "    instances = lstm_h[idx][\"instances\"]\n",
    "    for idy in range(len(instances)):\n",
    "        video_id = instances[idy][\"video_id\"]\n",
    "        # frame_str_end= {}\n",
    "        per_video = {}\n",
    "        if video_id in video_np:\n",
    "            d = {\"video_id\": video_id, \"on_show\": [instances[idy][\"frame_start\"], instances[idy][\"frame_end\"]]}\n",
    "            show_time.append(d)\n",
    "\n",
    "print(len(show_time))\n",
    "\n",
    "json_object = json.dumps(show_time, indent=4)\n",
    " \n",
    "# Writing to sample.json\n",
    "with open(\"D:\\Personalproject\\OpenHands\\json_output/show_time.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video_id': '58593', 'on_show': [1, -1]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "DIR_PKL = []\n",
    "\n",
    "# Open a file\n",
    "DIR_LSTM_PKL = \"D:/Personalproject/dataset/lstm_pkl/\"\n",
    "\n",
    "dirs = os.listdir(DIR_LSTM_PKL)\n",
    "# This would print all the files and directories\n",
    "mediapipe_holistic_minimal_27 =  [0, 2, 5, 11, 12, 13, 14, 33, 37, 38, 41, 42, 45, 46, 49, 50, 53, 54, 58, 59, 62, 63, 66, 67, 70, 71, 74],\n",
    "points =  list(mediapipe_holistic_minimal_27)\n",
    "\n",
    "for idx in range(len(dirs)):\n",
    "    DIR_PKL.append(dirs[idx])\n",
    "print(len(DIR_PKL))\n",
    "\n",
    "print(\"\\n\")\n",
    "for idy in range(len(DIR_PKL)):\n",
    "    DIR_PKL_VIDEO =  DIR_LSTM_PKL + DIR_PKL[idy]\n",
    "    video_name = DIR_PKL[idy].split(\".\")[0]\n",
    "    print(\" ==== {}\".format(video_name))\n",
    "\n",
    "    minimal_27 = []\n",
    "\n",
    "    data = pickle. load(open(DIR_PKL_VIDEO, \"rb\"))\n",
    "    keypoints = data[\"keypoints\"]\n",
    "    \n",
    "    print(\"NUM_FRAME OF VIDEO: {}\".format(len(keypoints)))\n",
    "    for idz in range((keypoints)):\n",
    "        frame = keypoints[idz]\n",
    "        d = []\n",
    "        for idw in points:\n",
    "            d.append(frame[idw])\n",
    "        reshape = np.reshape(d, (27,3))\n",
    "        # print(np.shape(reshape))\n",
    "        minimal_27.append(reshape)\n",
    "    print(\"minimal_27: {}, video {}\".format(np.shape(minimal_27), video_name))\n",
    "    total_lm3d = np.array(minimal_27)\n",
    "    dir_Save = \"D:\\Personalproject\\OpenHands\\data_out\"\n",
    "    save_path = \"{}/{}\".format(dir_Save,video_name)\n",
    "    np.save(save_path,total_lm3d)\n",
    "    print(\"Done! {}\".format(idy))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Personalproject/dataset/lstm_pkl/65050.pkl\n",
      "NUM_FRAME OF VIDEO 65050: 80\n",
      "D:/Personalproject/dataset/lstm_pkl/01962.pkl\n",
      "NUM_FRAME OF VIDEO 01962: 54\n",
      "D:/Personalproject/dataset/lstm_pkl/65051.pkl\n",
      "NUM_FRAME OF VIDEO 65051: 87\n",
      "D:/Personalproject/dataset/lstm_pkl/01955.pkl\n",
      "NUM_FRAME OF VIDEO 01955: 119\n",
      "D:/Personalproject/dataset/lstm_pkl/01965.pkl\n",
      "NUM_FRAME OF VIDEO 01965: 106\n",
      "D:/Personalproject/dataset/lstm_pkl/01956.pkl\n",
      "NUM_FRAME OF VIDEO 01956: 40\n",
      "D:/Personalproject/dataset/lstm_pkl/01957.pkl\n",
      "NUM_FRAME OF VIDEO 01957: 108\n",
      "D:/Personalproject/dataset/lstm_pkl/01960.pkl\n",
      "NUM_FRAME OF VIDEO 01960: 60\n",
      "D:/Personalproject/dataset/lstm_pkl/65343.pkl\n",
      "NUM_FRAME OF VIDEO 65343: 75\n",
      "D:/Personalproject/dataset/lstm_pkl/10185.pkl\n",
      "NUM_FRAME OF VIDEO 10185: 44\n",
      "D:/Personalproject/dataset/lstm_pkl/10187.pkl\n",
      "NUM_FRAME OF VIDEO 10187: 95\n",
      "D:/Personalproject/dataset/lstm_pkl/10188.pkl\n",
      "NUM_FRAME OF VIDEO 10188: 85\n",
      "D:/Personalproject/dataset/lstm_pkl/10190.pkl\n",
      "NUM_FRAME OF VIDEO 10190: 61\n",
      "D:/Personalproject/dataset/lstm_pkl/10183.pkl\n",
      "NUM_FRAME OF VIDEO 10183: 71\n",
      "D:/Personalproject/dataset/lstm_pkl/10194.pkl\n",
      "NUM_FRAME OF VIDEO 10194: 100\n",
      "D:/Personalproject/dataset/lstm_pkl/10195.pkl\n",
      "NUM_FRAME OF VIDEO 10195: 64\n",
      "D:/Personalproject/dataset/lstm_pkl/10197.pkl\n",
      "NUM_FRAME OF VIDEO 10197: 96\n",
      "D:/Personalproject/dataset/lstm_pkl/68033.pkl\n",
      "NUM_FRAME OF VIDEO 68033: 108\n",
      "D:/Personalproject/dataset/lstm_pkl/14899.pkl\n",
      "NUM_FRAME OF VIDEO 14899: 74\n",
      "D:/Personalproject/dataset/lstm_pkl/14900.pkl\n",
      "NUM_FRAME OF VIDEO 14900: 100\n",
      "D:/Personalproject/dataset/lstm_pkl/14882.pkl\n",
      "NUM_FRAME OF VIDEO 14882: 108\n",
      "D:/Personalproject/dataset/lstm_pkl/14903.pkl\n",
      "NUM_FRAME OF VIDEO 14903: 82\n",
      "D:/Personalproject/dataset/lstm_pkl/14883.pkl\n",
      "NUM_FRAME OF VIDEO 14883: 24\n",
      "D:/Personalproject/dataset/lstm_pkl/14884.pkl\n",
      "NUM_FRAME OF VIDEO 14884: 38\n",
      "D:/Personalproject/dataset/lstm_pkl/14885.pkl\n",
      "NUM_FRAME OF VIDEO 14885: 26\n",
      "D:/Personalproject/dataset/lstm_pkl/14886.pkl\n",
      "NUM_FRAME OF VIDEO 14886: 38\n",
      "D:/Personalproject/dataset/lstm_pkl/65445.pkl\n",
      "NUM_FRAME OF VIDEO 65445: 52\n",
      "D:/Personalproject/dataset/lstm_pkl/14887.pkl\n",
      "NUM_FRAME OF VIDEO 14887: 62\n",
      "D:/Personalproject/dataset/lstm_pkl/14888.pkl\n",
      "NUM_FRAME OF VIDEO 14888: 66\n",
      "D:/Personalproject/dataset/lstm_pkl/14893.pkl\n",
      "NUM_FRAME OF VIDEO 14893: 43\n",
      "D:/Personalproject/dataset/lstm_pkl/14894.pkl\n",
      "NUM_FRAME OF VIDEO 14894: 39\n",
      "D:/Personalproject/dataset/lstm_pkl/14895.pkl\n",
      "NUM_FRAME OF VIDEO 14895: 105\n",
      "D:/Personalproject/dataset/lstm_pkl/14896.pkl\n",
      "NUM_FRAME OF VIDEO 14896: 121\n",
      "D:/Personalproject/dataset/lstm_pkl/14898.pkl\n",
      "NUM_FRAME OF VIDEO 14898: 92\n",
      "D:/Personalproject/dataset/lstm_pkl/28557.pkl\n",
      "NUM_FRAME OF VIDEO 28557: 2001\n",
      "D:/Personalproject/dataset/lstm_pkl/66047.pkl\n",
      "NUM_FRAME OF VIDEO 66047: 65\n",
      "D:/Personalproject/dataset/lstm_pkl/28789.pkl\n",
      "NUM_FRAME OF VIDEO 28789: 115\n",
      "D:/Personalproject/dataset/lstm_pkl/28790.pkl\n",
      "NUM_FRAME OF VIDEO 28790: 53\n",
      "D:/Personalproject/dataset/lstm_pkl/28791.pkl\n",
      "NUM_FRAME OF VIDEO 28791: 30\n",
      "D:/Personalproject/dataset/lstm_pkl/28794.pkl\n",
      "NUM_FRAME OF VIDEO 28794: 106\n",
      "D:/Personalproject/dataset/lstm_pkl/66111.pkl\n",
      "NUM_FRAME OF VIDEO 66111: 72\n",
      "D:/Personalproject/dataset/lstm_pkl/35454.pkl\n",
      "NUM_FRAME OF VIDEO 35454: 104\n",
      "D:/Personalproject/dataset/lstm_pkl/35455.pkl\n",
      "NUM_FRAME OF VIDEO 35455: 121\n",
      "D:/Personalproject/dataset/lstm_pkl/35456.pkl\n",
      "NUM_FRAME OF VIDEO 35456: 118\n",
      "D:/Personalproject/dataset/lstm_pkl/35458.pkl\n",
      "NUM_FRAME OF VIDEO 35458: 49\n",
      "D:/Personalproject/dataset/lstm_pkl/35460.pkl\n",
      "NUM_FRAME OF VIDEO 35460: 79\n",
      "D:/Personalproject/dataset/lstm_pkl/35461.pkl\n",
      "NUM_FRAME OF VIDEO 35461: 102\n",
      "D:/Personalproject/dataset/lstm_pkl/35452.pkl\n",
      "NUM_FRAME OF VIDEO 35452: 106\n",
      "D:/Personalproject/dataset/lstm_pkl/35462.pkl\n",
      "NUM_FRAME OF VIDEO 35462: 109\n",
      "D:/Personalproject/dataset/lstm_pkl/35463.pkl\n",
      "NUM_FRAME OF VIDEO 35463: 117\n",
      "D:/Personalproject/dataset/lstm_pkl/35467.pkl\n",
      "NUM_FRAME OF VIDEO 35467: 85\n",
      "D:/Personalproject/dataset/lstm_pkl/35453.pkl\n",
      "NUM_FRAME OF VIDEO 35453: 88\n",
      "D:/Personalproject/dataset/lstm_pkl/39511.pkl\n",
      "NUM_FRAME OF VIDEO 39511: 38\n",
      "D:/Personalproject/dataset/lstm_pkl/39512.pkl\n",
      "NUM_FRAME OF VIDEO 39512: 57\n",
      "D:/Personalproject/dataset/lstm_pkl/39514.pkl\n",
      "NUM_FRAME OF VIDEO 39514: 82\n",
      "D:/Personalproject/dataset/lstm_pkl/39504.pkl\n",
      "NUM_FRAME OF VIDEO 39504: 75\n",
      "D:/Personalproject/dataset/lstm_pkl/39505.pkl\n",
      "NUM_FRAME OF VIDEO 39505: 81\n",
      "D:/Personalproject/dataset/lstm_pkl/39507.pkl\n",
      "NUM_FRAME OF VIDEO 39507: 81\n",
      "D:/Personalproject/dataset/lstm_pkl/39510.pkl\n",
      "NUM_FRAME OF VIDEO 39510: 45\n",
      "D:/Personalproject/dataset/lstm_pkl/53340.pkl\n",
      "NUM_FRAME OF VIDEO 53340: 101\n",
      "D:/Personalproject/dataset/lstm_pkl/53341.pkl\n",
      "NUM_FRAME OF VIDEO 53341: 66\n",
      "D:/Personalproject/dataset/lstm_pkl/53343.pkl\n",
      "NUM_FRAME OF VIDEO 53343: 104\n",
      "D:/Personalproject/dataset/lstm_pkl/53344.pkl\n",
      "NUM_FRAME OF VIDEO 53344: 97\n",
      "D:/Personalproject/dataset/lstm_pkl/53345.pkl\n",
      "NUM_FRAME OF VIDEO 53345: 171\n",
      "D:/Personalproject/dataset/lstm_pkl/53347.pkl\n",
      "NUM_FRAME OF VIDEO 53347: 29\n",
      "D:/Personalproject/dataset/lstm_pkl/68172.pkl\n",
      "NUM_FRAME OF VIDEO 68172: 101\n",
      "D:/Personalproject/dataset/lstm_pkl/58594.pkl\n",
      "NUM_FRAME OF VIDEO 58594: 86\n",
      "D:/Personalproject/dataset/lstm_pkl/58596.pkl\n",
      "NUM_FRAME OF VIDEO 58596: 95\n",
      "D:/Personalproject/dataset/lstm_pkl/58597.pkl\n",
      "NUM_FRAME OF VIDEO 58597: 111\n",
      "D:/Personalproject/dataset/lstm_pkl/58598.pkl\n",
      "NUM_FRAME OF VIDEO 58598: 78\n",
      "D:/Personalproject/dataset/lstm_pkl/58600.pkl\n",
      "NUM_FRAME OF VIDEO 58600: 66\n",
      "D:/Personalproject/dataset/lstm_pkl/58589.pkl\n",
      "NUM_FRAME OF VIDEO 58589: 99\n",
      "D:/Personalproject/dataset/lstm_pkl/58590.pkl\n",
      "NUM_FRAME OF VIDEO 58590: 85\n",
      "D:/Personalproject/dataset/lstm_pkl/58591.pkl\n",
      "NUM_FRAME OF VIDEO 58591: 83\n",
      "D:/Personalproject/dataset/lstm_pkl/58592.pkl\n",
      "NUM_FRAME OF VIDEO 58592: 65\n",
      "D:/Personalproject/dataset/lstm_pkl/58593.pkl\n",
      "NUM_FRAME OF VIDEO 58593: 33\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "DIR_PKL = []\n",
    "\n",
    "# Open a file\n",
    "DIR_LSTM_PKL = \"D:/Personalproject/dataset/lstm_pkl/\"\n",
    "\n",
    "dirs = os.listdir(DIR_LSTM_PKL)\n",
    "# This would print all the files and directories\n",
    "mediapipe_holistic_minimal_27 =  [0, 2, 5, 11, 12, 13, 14, 33, 37, 38, 41, 42, 45, 46, 49, 50, 53, 54, 58, 59, 62, 63, 66, 67, 70, 71, 74],\n",
    "points =  list(mediapipe_holistic_minimal_27)\n",
    "\n",
    "show_time = json.load(open(\"D:\\Personalproject\\OpenHands\\json_output\\show_time.json\", \"r\"))\n",
    "json_object = []\n",
    "num_frames_per_video = []\n",
    "for idx in range(len(show_time)):\n",
    "    # DIR_PKL_VIDEO =  DIR_LSTM_PKL + DIR_PKL[idy]\n",
    "    # video_name = DIR_PKL[idy].split(\".\")[0]\n",
    "    # print(\" ==== {}\".format(video_name))\n",
    "    video_name = show_time[idx][\"video_id\"]\n",
    "    # num_frames = tuple(show_time[idx][\"on_show\"])\n",
    "\n",
    "    DIR_PKL_VIDEO = DIR_LSTM_PKL + video_name + \".pkl\"\n",
    "    print(DIR_PKL_VIDEO)\n",
    "    minimal_27 = []\n",
    "\n",
    "    data = pickle. load(open(DIR_PKL_VIDEO, \"rb\"))\n",
    "    keypoints = data[\"keypoints\"]\n",
    "    \n",
    "    print(\"NUM_FRAME OF VIDEO {}: {}\".format(video_name,len(keypoints)))\n",
    "\n",
    "    if video_name not in [\"28557\", \"53345\"]:\n",
    "\n",
    "        num_frames_per_video.append(len(keypoints))\n",
    "    d = {\"video_id\": video_name, \"num_frames\" : len(keypoints)}\n",
    "    json_object.append(d)\n",
    "    \n",
    "    for idz in range(len(keypoints)):\n",
    "        frame = keypoints[idz]\n",
    "        d = []\n",
    "        for idw in points:\n",
    "            d.append(frame[idw])\n",
    "        reshape = np.reshape(d, (27,3))\n",
    "        # print(np.shape(reshape))\n",
    "        minimal_27.append(reshape)\n",
    "\n",
    "#     print(\"minimal_27: {}, video {}\".format(np.shape(minimal_27), video_name))\n",
    "#     total_lm3d = np.array(minimal_27)\n",
    "#     dir_Save = \"D:/Personalproject/OpenHands/npy_lstm\"\n",
    "#     save_path = \"{}/{}\".format(dir_Save,video_name)\n",
    "\n",
    "#     np.save(save_path,total_lm3d)\n",
    "#     print(\"Done! {}\".format(idy))\n",
    "\n",
    "\n",
    "#     print(\"=\"*30)\n",
    "#     print(\"/n\")\n",
    "\n",
    "# json_object = json.dumps(json_object, indent=4)\n",
    " \n",
    "# # Writing to sample.json\n",
    "# with open(\"D:\\Personalproject\\OpenHands\\json_output/num_frame_of_video.json\", \"w\") as outfile:\n",
    "#     outfile.write(json_object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = max(num_frames_per_video)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171\n",
      "minimal_27: (106, 27, 3), video 53345\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "data = pickle. load(open(\"D:\\Personalproject\\dataset\\lstm_pkl/53345.pkl\", \"rb\"))\n",
    "\n",
    "keypoints = data[\"keypoints\"]\n",
    "print(len(keypoints))\n",
    "\n",
    "video_name = \"53345\"\n",
    "\n",
    "minimal_27 = []\n",
    "num_frame = range(61,167)\n",
    "for idz in num_frame:\n",
    "        frame = keypoints[idz]\n",
    "        d = []\n",
    "        for idw in points:\n",
    "            d.append(frame[idw])\n",
    "        reshape = np.reshape(d, (27,3))\n",
    "        # print(np.shape(reshape))\n",
    "        minimal_27.append(reshape)\n",
    "\n",
    "print(\"minimal_27: {}, video {}\".format(np.shape(minimal_27), video_name))\n",
    "total_lm3d = np.array(minimal_27)\n",
    "dir_Save = \"D:/Personalproject/OpenHands/npy_lstm\"\n",
    "save_path = \"{}/{}\".format(dir_Save,video_name)\n",
    "np.save(save_path,total_lm3d)\n",
    "\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "data = pickle. load(open(\"D:\\Personalproject\\dataset\\lstm_pkl/53345.pkl\", \"rb\"))\n",
    "\n",
    "keypoints = data[\"keypoints\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/Personalproject/OpenHands/npy_lstm/28557'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106, 27, 3)\n"
     ]
    }
   ],
   "source": [
    "a = np.load(\"D:/Personalproject/OpenHands/npy_lstm/53345.npy\")\n",
    "\n",
    "print(np.shape(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Max frames onshow in lstm_npy is 121 - video 35455\n",
    "\n",
    "=> Tachs npy vao cac file theo class\n",
    "=> format dataset for format (lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "data = pickle. load(open(\"D:\\Personalproject\\dataset\\lstm_pkl/01956.pkl\", \"rb\"))\n",
    "\n",
    "keypoints = data[\"keypoints\"]\n",
    "print(len(keypoints))\n",
    "print(np.shape(keypoints))\n",
    "print(keypoints[20][32])\n",
    "\n",
    "print(keypoints[39])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    IF len(data) < 121\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62, 27, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.load(\"D:/Personalproject/OpenHands/npy_lstm/14887.npy\")\n",
    "\n",
    "print(np.shape(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import numpy as np\n",
    "import os, glob\n",
    "\n",
    "DIR_NPY =  \"D:/Personalproject/OpenHands/npy_lstm\"\n",
    "file_name = []\n",
    "for file in os.listdir(DIR_NPY):\n",
    "    file_name.append(file)\n",
    "\n",
    "# print(file_name[0])\n",
    "\n",
    "for idx in range(len(file_name)):\n",
    "# for idx in range(2):\n",
    "    a = 0\n",
    "    DIR_LOAD = DIR_NPY + \"/\" +  file_name[idx]\n",
    "    print(\"Video: \",file_name[idx])\n",
    "    video_npy =  np.load(DIR_LOAD)\n",
    "    d = []\n",
    "    for idy in range(len(video_npy)):\n",
    "        a = video_npy[idy].flatten()\n",
    "        d.append(a)\n",
    "    print(\"Shape of video before concate: {}\".format(np.shape(d)))\n",
    "    if len(d)<121:\n",
    "        num_lost =  121 - len(d)\n",
    "        print(num_lost)\n",
    "        a = np.zeros((num_lost,81))\n",
    "        print(\"Num frame lost: {}\".format(num_lost))\n",
    "        d = np.concatenate([d, a])\n",
    "    \n",
    "    print(\"LSTM - 21 : {}, video {}\".format(np.shape(d), file_name[idx]))\n",
    "    total_lm3d = np.array(d)\n",
    "    dir_Save = \"D:/Personalproject/OpenHands/npy_lstm_21\"\n",
    "    save_path = \"{}/{}\".format(dir_Save,file_name[idx])\n",
    "    np.save(save_path,total_lm3d)\n",
    "    print(\"=\"*30)\n",
    "\n",
    "    # print(np.shape(d))\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "# for idx in range(len(data)):\n",
    "#     a = data[idx].flatten()\n",
    "#     d.append(a)\n",
    "\n",
    "# print(len(d))\n",
    "# print(np.shape(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [\"deaf\", \"medicine\", \"sore throat\", \"tired\", \"i\", \"allergy\", \"often\", \"check\"]\n",
    "\n",
    "label_map = {label:num for num, label in enumerate(actions)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deaf': 0,\n",
       " 'medicine': 1,\n",
       " 'sore throat': 2,\n",
       " 'tired': 3,\n",
       " 'i': 4,\n",
       " 'allergy': 5,\n",
       " 'often': 6,\n",
       " 'check': 7}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01955\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import numpy as np\n",
    "import os, glob\n",
    "\n",
    "DIR_NPY =  \"D:/Personalproject/OpenHands/npy_lstm_21\"\n",
    "file_name = []\n",
    "video_names = []\n",
    "for file in os.listdir(DIR_NPY):\n",
    "    file_name.append(file)\n",
    "    video_name = file.split(\".\")[0]\n",
    "    video_names.append(video_name)\n",
    "\n",
    "for idx in range(len(video_names)):\n",
    "    \n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for action in actions:\n",
    "    labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "DIR_MAKE = \"D:/Personalproject/lstm_train/\"\n",
    "for action in actions:\n",
    "    # print(action)\n",
    "    folder_dir = DIR_MAKE + action\n",
    "    os.makedirs(folder_dir)\n",
    "    print(\"Done!\")\n",
    "    # os.makedirs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import os, glob, shutil\n",
    "\n",
    "f = open(\"D:\\Personalproject\\OpenHands\\json_output\\LSTM_H.json\", \"r\")\n",
    "lstm_h = json.load(f)\n",
    "\n",
    "# len(lstm_h)\n",
    "DIR_NPY = \"D:/Personalproject/OpenHands/npy_lstm_21/\"\n",
    "DIR_COPY = \"D:/Personalproject/lstm_train/\"\n",
    "count = 0\n",
    "d = []\n",
    "\n",
    "file_name = []\n",
    "file_npy = []\n",
    "for file in os.listdir(DIR_NPY):\n",
    "    file_name.append(file)\n",
    "    file_npy.append(file.split(\".\")[0])\n",
    "\n",
    "for idx in range(len(lstm_h)):\n",
    "    action = lstm_h[idx][\"gloss\"]\n",
    "    instances = lstm_h[idx][\"instances\"]\n",
    "    # print(len(instances))\n",
    "    for idy in range(len(instances)):\n",
    "        video_id = instances[idy][\"video_id\"]\n",
    "        class_map = {}\n",
    "\n",
    "        if video_id in file_npy:\n",
    "\n",
    "        # print(video_id)\n",
    "            file_path = os.path.join(DIR_NPY,  video_id+ \".npy\")\n",
    "            save_path  = os.path.join(DIR_COPY, action ,video_id + \".npy\")\n",
    "            shutil.copy(file_path, save_path)\n",
    "            print(\"Done: {}\".format(video_id))\n",
    "            count +=1\n",
    "            class_map = {\"video_name\": video_id, \"action\": action}\n",
    "            d.append(class_map)\n",
    "        \n",
    "            \n",
    "json_object = json.dumps(d, indent=4)\n",
    "save_dir = \"D:\\Personalproject\\OpenHands\\json_output\\lstm_class_map.json\"\n",
    "with open(save_dir, \"w\") as outfile:\n",
    "  outfile.write(json_object)\n",
    "print(len(json_object))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "actions = [\"deaf\", \"medicine\", \"sore throat\", \"tired\", \"i\", \"allergy\", \"often\", \"check\"]\n",
    "\n",
    "label_map = {label:num for num, label in enumerate(actions)}\n",
    "\n",
    "DIR_COPY = \"D:/Personalproject/lstm_train/\"\n",
    "\n",
    "sequences, labels = [], []\n",
    "for action in actions:\n",
    "    ACTION_DIR = DIR_COPY + action\n",
    "    window = []\n",
    "\n",
    "    for file in os.listdir(ACTION_DIR):\n",
    "        # res = np.load(ACTION)\n",
    "        NPY_DIR = os.path.join(ACTION_DIR, file)\n",
    "        # print(NPY_DIR)\n",
    "        res = np.load(NPY_DIR)\n",
    "        sequences.append(res)\n",
    "        labels.append(label_map[action])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76, 121, 81)\n",
      "(76,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(sequences))\n",
    "print(np.shape(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76, 121, 81)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 121, 81)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"D:\\Personalproject\\OpenHands\\Logs\"\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions_z = np.array(actions)\n",
    "actions_z.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30,81)))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(actions_z.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [.7, 0.2, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deaf'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(res)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=120, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 121, 64)           37376     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 121, 128)          98816     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 121, 128)          131584    \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 121, 64)           49408     \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 264       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 356,712\n",
      "Trainable params: 356,712\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 781ms/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.21333086 0.16203274 0.08727344 0.13349786 0.07649505 0.11356144\n",
      "  0.08883899 0.12496968]\n",
      " [0.21333086 0.16203274 0.08727344 0.13349786 0.07649505 0.11356144\n",
      "  0.08883899 0.12496968]\n",
      " [0.21333086 0.16203274 0.08727344 0.13349786 0.07649505 0.11356144\n",
      "  0.08883899 0.12496968]\n",
      " [0.21333086 0.16203274 0.08727344 0.13349786 0.07649505 0.11356144\n",
      "  0.08883899 0.12496968]]\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deaf'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(res[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'often'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(y_test[2])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 2).\n",
       "Contents of stderr:\n",
       "usage: tensorboard [-h] [--helpfull] [--logdir PATH] [--logdir_spec PATH_SPEC]\n",
       "                   [--host ADDR] [--bind_all] [--port PORT]\n",
       "                   [--reuse_port BOOL] [--load_fast {false,auto,true}]\n",
       "                   [--extra_data_server_flags EXTRA_DATA_SERVER_FLAGS]\n",
       "                   [--grpc_creds_type {local,ssl,ssl_dev}]\n",
       "                   [--grpc_data_provider PORT] [--purge_orphaned_data BOOL]\n",
       "                   [--db URI] [--db_import] [--inspect] [--version_tb]\n",
       "                   [--tag TAG] [--event_file PATH] [--path_prefix PATH]\n",
       "                   [--window_title TEXT] [--max_reload_threads COUNT]\n",
       "                   [--reload_interval SECONDS] [--reload_task TYPE]\n",
       "                   [--reload_multifile BOOL]\n",
       "                   [--reload_multifile_inactive_secs SECONDS]\n",
       "                   [--generic_data TYPE]\n",
       "                   [--samples_per_plugin SAMPLES_PER_PLUGIN]\n",
       "                   [--detect_file_replacement BOOL]\n",
       "                   [--whatif-use-unsafe-custom-prediction YOUR_CUSTOM_PREDICT_FUNCTION.py]\n",
       "                   [--whatif-data-dir PATH]\n",
       "                   {serve,dev} ...\n",
       "tensorboard: error: argument {serve,dev}: invalid choice: '--' (choose from 'serve', 'dev')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard -- logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_SLT_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = 'action1.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Personalproject\\OpenHands\\helper.ipynb Cell 82\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Personalproject/OpenHands/helper.ipynb#Y152sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mload_weights(\u001b[39m'\u001b[39;49m\u001b[39maction1.h5\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\bvinh\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\bvinh\\anaconda3\\envs\\tf\\lib\\site-packages\\h5py\\_hl\\files.py:533\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, **kwds)\u001b[0m\n\u001b[0;32m    525\u001b[0m     fapl \u001b[39m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    526\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    527\u001b[0m                      alignment_threshold\u001b[39m=\u001b[39malignment_threshold,\n\u001b[0;32m    528\u001b[0m                      alignment_interval\u001b[39m=\u001b[39malignment_interval,\n\u001b[0;32m    529\u001b[0m                      \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    530\u001b[0m     fcpl \u001b[39m=\u001b[39m make_fcpl(track_order\u001b[39m=\u001b[39mtrack_order, fs_strategy\u001b[39m=\u001b[39mfs_strategy,\n\u001b[0;32m    531\u001b[0m                      fs_persist\u001b[39m=\u001b[39mfs_persist, fs_threshold\u001b[39m=\u001b[39mfs_threshold,\n\u001b[0;32m    532\u001b[0m                      fs_page_size\u001b[39m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 533\u001b[0m     fid \u001b[39m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[39m=\u001b[39mswmr)\n\u001b[0;32m    535\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(libver, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    536\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_libver \u001b[39m=\u001b[39m libver\n",
      "File \u001b[1;32mc:\\Users\\bvinh\\anaconda3\\envs\\tf\\lib\\site-packages\\h5py\\_hl\\files.py:226\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[39mif\u001b[39;00m swmr \u001b[39mand\u001b[39;00m swmr_support:\n\u001b[0;32m    225\u001b[0m         flags \u001b[39m|\u001b[39m\u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 226\u001b[0m     fid \u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39;49mopen(name, flags, fapl\u001b[39m=\u001b[39;49mfapl)\n\u001b[0;32m    227\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    228\u001b[0m     fid \u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39mopen(name, h5f\u001b[39m.\u001b[39mACC_RDWR, fapl\u001b[39m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = 'action1.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "model.load_weights('model_SLT_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 3],\n",
       "        [0, 1]],\n",
       "\n",
       "       [[3, 0],\n",
       "        [1, 0]],\n",
       "\n",
       "       [[3, 0],\n",
       "        [1, 0]],\n",
       "\n",
       "       [[3, 0],\n",
       "        [1, 0]]], dtype=int64)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(ytrue, yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of FixedLocator locations (2), usually from a call to set_ticks, does not match the number of ticklabels (4).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Personalproject\\OpenHands\\helper.ipynb Cell 87\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Personalproject/OpenHands/helper.ipynb#Y163sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m confusion_matrix \u001b[39min\u001b[39;00m confusion_matrices:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Personalproject/OpenHands/helper.ipynb#Y163sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     disp \u001b[39m=\u001b[39m ConfusionMatrixDisplay(confusion_matrix, display_labels\u001b[39m=\u001b[39mytrue)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Personalproject/OpenHands/helper.ipynb#Y163sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     disp\u001b[39m.\u001b[39;49mplot(include_values\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, cmap\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mviridis\u001b[39;49m\u001b[39m\"\u001b[39;49m, ax\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, xticks_rotation\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mvertical\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Personalproject/OpenHands/helper.ipynb#Y163sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\bvinh\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_plot\\confusion_matrix.py:172\u001b[0m, in \u001b[0;36mConfusionMatrixDisplay.plot\u001b[1;34m(self, include_values, cmap, xticks_rotation, values_format, ax, colorbar, im_kw)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[39mif\u001b[39;00m colorbar:\n\u001b[0;32m    171\u001b[0m     fig\u001b[39m.\u001b[39mcolorbar(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mim_, ax\u001b[39m=\u001b[39max)\n\u001b[1;32m--> 172\u001b[0m ax\u001b[39m.\u001b[39;49mset(\n\u001b[0;32m    173\u001b[0m     xticks\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49marange(n_classes),\n\u001b[0;32m    174\u001b[0m     yticks\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49marange(n_classes),\n\u001b[0;32m    175\u001b[0m     xticklabels\u001b[39m=\u001b[39;49mdisplay_labels,\n\u001b[0;32m    176\u001b[0m     yticklabels\u001b[39m=\u001b[39;49mdisplay_labels,\n\u001b[0;32m    177\u001b[0m     ylabel\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mTrue label\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    178\u001b[0m     xlabel\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPredicted label\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    179\u001b[0m )\n\u001b[0;32m    181\u001b[0m ax\u001b[39m.\u001b[39mset_ylim((n_classes \u001b[39m-\u001b[39m \u001b[39m0.5\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m0.5\u001b[39m))\n\u001b[0;32m    182\u001b[0m plt\u001b[39m.\u001b[39msetp(ax\u001b[39m.\u001b[39mget_xticklabels(), rotation\u001b[39m=\u001b[39mxticks_rotation)\n",
      "File \u001b[1;32mc:\\Users\\bvinh\\anaconda3\\envs\\tf\\lib\\site-packages\\matplotlib\\artist.py:117\u001b[0m, in \u001b[0;36mArtist.__init_subclass__.<locals>.<lambda>\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mset, \u001b[39m'\u001b[39m\u001b[39m_autogenerated_signature\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    110\u001b[0m     \u001b[39m# Don't overwrite cls.set if the subclass or one of its parents\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     \u001b[39m# has defined a set method set itself.\u001b[39;00m\n\u001b[0;32m    112\u001b[0m     \u001b[39m# If there was no explicit definition, cls.set is inherited from\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[39m# the hierarchy of auto-generated set methods, which hold the\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     \u001b[39m# flag _autogenerated_signature.\u001b[39;00m\n\u001b[0;32m    115\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mset \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m \u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Artist\u001b[39m.\u001b[39mset(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mset\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mset\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    119\u001b[0m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mset\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.set\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\bvinh\\anaconda3\\envs\\tf\\lib\\site-packages\\matplotlib\\artist.py:1194\u001b[0m, in \u001b[0;36mArtist.set\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1191\u001b[0m     \u001b[39m# docstring and signature are auto-generated via\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m     \u001b[39m# Artist._update_set_signature_and_docstring() at the end of the\u001b[39;00m\n\u001b[0;32m   1193\u001b[0m     \u001b[39m# module.\u001b[39;00m\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_internal_update(cbook\u001b[39m.\u001b[39;49mnormalize_kwargs(kwargs, \u001b[39mself\u001b[39;49m))\n",
      "File \u001b[1;32mc:\\Users\\bvinh\\anaconda3\\envs\\tf\\lib\\site-packages\\matplotlib\\artist.py:1186\u001b[0m, in \u001b[0;36mArtist._internal_update\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m   1179\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_internal_update\u001b[39m(\u001b[39mself\u001b[39m, kwargs):\n\u001b[0;32m   1180\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m \u001b[39m    Update artist properties without prenormalizing them, but generating\u001b[39;00m\n\u001b[0;32m   1182\u001b[0m \u001b[39m    errors as if calling `set`.\u001b[39;00m\n\u001b[0;32m   1183\u001b[0m \n\u001b[0;32m   1184\u001b[0m \u001b[39m    The lack of prenormalization is to maintain backcompatibility.\u001b[39;00m\n\u001b[0;32m   1185\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1186\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_props(\n\u001b[0;32m   1187\u001b[0m         kwargs, \u001b[39m\"\u001b[39;49m\u001b[39m{cls.__name__}\u001b[39;49;00m\u001b[39m.set() got an unexpected keyword argument \u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m   1188\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m{prop_name!r}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\bvinh\\anaconda3\\envs\\tf\\lib\\site-packages\\matplotlib\\artist.py:1162\u001b[0m, in \u001b[0;36mArtist._update_props\u001b[1;34m(self, props, errfmt)\u001b[0m\n\u001b[0;32m   1159\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(func):\n\u001b[0;32m   1160\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[0;32m   1161\u001b[0m                     errfmt\u001b[39m.\u001b[39mformat(\u001b[39mcls\u001b[39m\u001b[39m=\u001b[39m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m), prop_name\u001b[39m=\u001b[39mk))\n\u001b[1;32m-> 1162\u001b[0m             ret\u001b[39m.\u001b[39mappend(func(v))\n\u001b[0;32m   1163\u001b[0m \u001b[39mif\u001b[39;00m ret:\n\u001b[0;32m   1164\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpchanged()\n",
      "File \u001b[1;32mc:\\Users\\bvinh\\anaconda3\\envs\\tf\\lib\\site-packages\\matplotlib\\axes\\_base.py:73\u001b[0m, in \u001b[0;36m_axis_method_wrapper.__set_name__.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m get_method(\u001b[39mself\u001b[39m)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bvinh\\anaconda3\\envs\\tf\\lib\\site-packages\\matplotlib\\axis.py:1968\u001b[0m, in \u001b[0;36mAxis._set_ticklabels\u001b[1;34m(self, labels, fontdict, minor, **kwargs)\u001b[0m\n\u001b[0;32m   1966\u001b[0m \u001b[39mif\u001b[39;00m fontdict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1967\u001b[0m     kwargs\u001b[39m.\u001b[39mupdate(fontdict)\n\u001b[1;32m-> 1968\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_ticklabels(labels, minor\u001b[39m=\u001b[39mminor, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bvinh\\anaconda3\\envs\\tf\\lib\\site-packages\\matplotlib\\axis.py:1890\u001b[0m, in \u001b[0;36mAxis.set_ticklabels\u001b[1;34m(self, ticklabels, minor, **kwargs)\u001b[0m\n\u001b[0;32m   1886\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(locator, mticker\u001b[39m.\u001b[39mFixedLocator):\n\u001b[0;32m   1887\u001b[0m     \u001b[39m# Passing [] as a list of ticklabels is often used as a way to\u001b[39;00m\n\u001b[0;32m   1888\u001b[0m     \u001b[39m# remove all tick labels, so only error for > 0 ticklabels\u001b[39;00m\n\u001b[0;32m   1889\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(locator\u001b[39m.\u001b[39mlocs) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(ticklabels) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(ticklabels) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 1890\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1891\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe number of FixedLocator locations\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1892\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(locator\u001b[39m.\u001b[39mlocs)\u001b[39m}\u001b[39;00m\u001b[39m), usually from a call to\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1893\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m set_ticks, does not match\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1894\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m the number of ticklabels (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(ticklabels)\u001b[39m}\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1895\u001b[0m     tickd \u001b[39m=\u001b[39m {loc: lab \u001b[39mfor\u001b[39;00m loc, lab \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(locator\u001b[39m.\u001b[39mlocs, ticklabels)}\n\u001b[0;32m   1896\u001b[0m     func \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_with_dict, tickd)\n",
      "\u001b[1;31mValueError\u001b[0m: The number of FixedLocator locations (2), usually from a call to set_ticks, does not match the number of ticklabels (4)."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# test_labels = [0, 1, 2, 1, 0]\n",
    "# y_pred      = [0, 1, 2, 1, 1]\n",
    "confusion_matrices = multilabel_confusion_matrix(ytrue, yhat)\n",
    "for confusion_matrix in confusion_matrices:\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix, display_labels=ytrue)\n",
    "    disp.plot(include_values=True, cmap=\"viridis\", ax=None, xticks_rotation=\"vertical\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ece2a44e751d19c62d50bfc568f1b312931526a32592d81a9518ee82e610ac3c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
